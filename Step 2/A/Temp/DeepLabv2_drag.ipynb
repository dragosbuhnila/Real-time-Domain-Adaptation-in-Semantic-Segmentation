{"cells":[{"cell_type":"markdown","metadata":{"id":"cbIwgK7-uZ0l"},"source":[]},{"cell_type":"markdown","metadata":{"id":"OiovToEGs9mz"},"source":["# Classic semantic segmentation network."]},{"cell_type":"markdown","metadata":{"id":"YwDm553BzPlB"},"source":["# LoveDA Dataset"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"cjuW8Yf0zO7K","executionInfo":{"status":"ok","timestamp":1734968841851,"user_tz":-60,"elapsed":268,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}},"outputId":"53cbdca9-f292-4f8f-9dcd-7bfea734c490"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive is already mounted.\n"]}],"source":["from google.colab import drive\n","import os\n","\n","if not os.path.exists('/content/drive'):  # Check if Drive is already mounted\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Drive is already mounted.\")\n","\n","dataset_path = '/content/drive/MyDrive/LoveDA/Train.zip'\n","if (os.path.exists(\"./Train\") == False):\n","    if (os.path.exists(dataset_path)):\n","        print(\"Dataset available on own drive, unzipping...\")\n","        !unzip {dataset_path} -d ./Train\n","    else:\n","        print(\"Downloading dataset...\")\n","        !wget -O Train.zip \"https://zenodo.org/records/5706578/files/Train.zip?download=1\"\n","        !unzip Train.zip -d ./Train"]},{"cell_type":"code","source":["# !cp /content/Train.zip /content/drive/MyDrive/LoveDA/Train.zip"],"metadata":{"id":"UoQPJb8aGsRS","executionInfo":{"status":"ok","timestamp":1734968842846,"user_tz":-60,"elapsed":284,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["if (not os.path.exists(\"./LoveDA\")):\n","  print(\"Cloning LoveDA repository...\")\n","  !git clone https://github.com/Junjue-Wang/LoveDA.git\n","\n","import sys\n","sys.path.append('/content/LoveDA/Semantic_Segmentation/data')"],"metadata":{"collapsed":true,"id":"8O6GwtLiI7DR","executionInfo":{"status":"ok","timestamp":1734968842847,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters\n"],"metadata":{"id":"sNc9IV2oI_XW"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"S49jvGKRNJlP","executionInfo":{"status":"ok","timestamp":1734968842847,"user_tz":-60,"elapsed":5,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"outputs":[],"source":["DEVICE = 'cuda' # 'cuda' or 'cpu'\n","\n","LR = 1e-3            # The initial Learning Rate\n","MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n","WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n","\n","NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n","STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n","GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n","\n","LOG_FREQUENCY = 10\n","\n","BATCH_SIZE = 1"]},{"cell_type":"markdown","source":["# DeepLabv2"],"metadata":{"id":"zptaYcw_KyyB"}},{"cell_type":"markdown","source":["### Model Definition"],"metadata":{"id":"thrVHTh6LGt1"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","affine_par = True\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        padding = dilation\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n","                               padding=padding, bias=False, dilation=dilation)\n","        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn2.parameters():\n","            i.requires_grad = False\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n","        for i in self.bn3.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ClassifierModule(nn.Module):\n","    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n","        super(ClassifierModule, self).__init__()\n","        self.conv2d_list = nn.ModuleList()\n","        for dilation, padding in zip(dilation_series, padding_series):\n","            self.conv2d_list.append(\n","                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n","                          dilation=dilation, bias=True))\n","\n","        for m in self.conv2d_list:\n","            m.weight.data.normal_(0, 0.01)\n","\n","    def forward(self, x):\n","        out = self.conv2d_list[0](x)\n","        for i in range(len(self.conv2d_list) - 1):\n","            out += self.conv2d_list[i + 1](x)\n","        return out\n","\n","\n","class ResNetMulti(nn.Module):\n","    def __init__(self, block, layers, num_classes):\n","        self.inplanes = 64\n","        super(ResNetMulti, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n","        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                m.weight.data.normal_(0, 0.01)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n","        downsample = None\n","        if (stride != 1\n","                or self.inplanes != planes * block.expansion\n","                or dilation == 2\n","                or dilation == 4):\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n","        for i in downsample._modules['1'].parameters():\n","            i.requires_grad = False\n","        layers = []\n","        layers.append(\n","            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, dilation=dilation))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        _, _, H, W = x.size()\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer6(x)\n","\n","        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n","\n","        if self.training == True:\n","            return x, None, None\n","\n","        return x\n","\n","    def get_1x_lr_params_no_scale(self):\n","        \"\"\"\n","        This generator returns all the parameters of the net except for\n","        the last classification layer. Note that for each batchnorm layer,\n","        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n","        any batchnorm parameter\n","        \"\"\"\n","        b = []\n","\n","        b.append(self.conv1)\n","        b.append(self.bn1)\n","        b.append(self.layer1)\n","        b.append(self.layer2)\n","        b.append(self.layer3)\n","        b.append(self.layer4)\n","\n","        for i in range(len(b)):\n","            for j in b[i].modules():\n","                jj = 0\n","                for k in j.parameters():\n","                    jj += 1\n","                    if k.requires_grad:\n","                        yield k\n","\n","    def get_10x_lr_params(self):\n","        \"\"\"\n","        This generator returns all the parameters for the last layer of the net,\n","        which does the classification of pixel into classes\n","        \"\"\"\n","        b = []\n","        if self.multi_level:\n","            b.append(self.layer5.parameters())\n","        b.append(self.layer6.parameters())\n","\n","        for j in range(len(b)):\n","            for i in b[j]:\n","                yield i\n","\n","    def optim_parameters(self, lr):\n","        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n","                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n","\n","\n","def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n","    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n","\n","    # Pretraining loading\n","    if pretrain:\n","        print('Deeplab pretraining loading...')\n","        saved_state_dict = torch.load(pretrain_model_path)\n","\n","        new_params = model.state_dict().copy()\n","        for i in saved_state_dict:\n","            i_parts = i.split('.')\n","            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n","        model.load_state_dict(new_params, strict=False)\n","\n","    return model"],"metadata":{"id":"CoF0v7IKKxYM","executionInfo":{"status":"ok","timestamp":1734968842847,"user_tz":-60,"elapsed":5,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kv4QKgqpD6Dr"},"source":["### Get Pre Trained weights"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKhjuuhxD9NP","executionInfo":{"status":"ok","timestamp":1734968845181,"user_tz":-60,"elapsed":2338,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}},"outputId":"25dcb655-9b23-4d18-a43a-dd59a1c9f58b","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"y-R5fJBKEhQF","executionInfo":{"status":"ok","timestamp":1734968845181,"user_tz":-60,"elapsed":5,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"outputs":[],"source":["import gdown\n","\n","# File ID and destination path\n","file_id = \"1ZX0UCXvJwqd2uBGCX7LI2n-DfMg3t74v\"\n","url = f\"https://drive.google.com/uc?id={file_id}\"\n","output = \"deeplab_resnet_pretrained_imagenet.pth\"\n","\n","# Download the file\n","if (os.path.exists(\"./deeplab_resnet_pretrained_imagenet.pth\") == False):\n","    print(\"Downloading deeplab_resnet_pretrained_imagenet.pth...\")\n","    gdown.download(url, output, quiet=False)\n"]},{"cell_type":"markdown","metadata":{"id":"3DwQcmOWpUxn"},"source":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"cWsxdJofLR_d"}},{"cell_type":"code","source":["!pip install ever-beta==0.2.3\n","!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n","!ln -s </path/to/LoveDA> ./LoveDA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"nKvi-anxL1iF","executionInfo":{"status":"ok","timestamp":1734968851351,"user_tz":-60,"elapsed":6175,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}},"outputId":"468db655-9097-49f1-991d-b898b744ed0f"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ever-beta in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ever-beta) (1.26.4)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from ever-beta) (3.12.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from ever-beta) (11.0.0)\n","Requirement already satisfied: albumentations>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from ever-beta) (1.4.20)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.10/dist-packages (from ever-beta) (2.17.1)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from ever-beta) (2024.12.12)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from ever-beta) (0.25.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ever-beta) (1.13.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from ever-beta) (3.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ever-beta) (4.67.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ever-beta) (2.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations>=0.4.2->ever-beta) (6.0.2)\n","Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations>=0.4.2->ever-beta) (2.10.3)\n","Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations>=0.4.2->ever-beta) (0.0.19)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations>=0.4.2->ever-beta) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations>=0.4.2->ever-beta) (4.10.0.84)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations>=0.4.2->ever-beta) (3.11.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (1.68.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (3.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (4.25.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.14->ever-beta) (3.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ever-beta) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ever-beta) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ever-beta) (2024.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->ever-beta) (0.2.13)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ever-beta) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ever-beta) (2.36.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->ever-beta) (0.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations>=0.4.2->ever-beta) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.14->ever-beta) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"Y8nlqvfeFpg0","executionInfo":{"status":"error","timestamp":1734968908411,"user_tz":-60,"elapsed":271,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}},"outputId":"252364f0-0c61-4740-ee8f-d53ae8134f90"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'LoveDADataset' from 'loveda' (/content/LoveDA/Semantic_Segmentation/data/loveda.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f6d95fe16b46>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mloveda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoveDADataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpretrain_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'deeplab_resnet_pretrained_imagenet.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'LoveDADataset' from 'loveda' (/content/LoveDA/Semantic_Segmentation/data/loveda.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from loveda import LoveDADataset\n","\n","pretrain_model_path = 'deeplab_resnet_pretrained_imagenet.pth'\n","num_classes = len(LABEL_MAP)\n","model = get_deeplab_v2(num_classes=num_classes, pretrain=True, pretrain_model_path=pretrain_model_path)\n","\n","#loss = SegmentationLoss(loss_config={'ce': True})\n","\n","# Example optimizer\n","optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","# Dataloader\n","train_dataset = LoveDADataset()\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gT7bVXshNCk4","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1734968851351,"user_tz":-60,"elapsed":8,"user":{"displayName":"Dragos Buhnila","userId":"07192742461106658715"}}},"outputs":[],"source":["# # from torch.backends import cudnn\n","# torch.cuda.empty_cache()\n","# # By default, everything is loaded to cpu\n","# net = model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","# # cudnn.benchmark # Calling this optimizes runtime\n","\n","# current_step = 0\n","# # Start iterating over the epochs\n","\n","# for epoch in range(NUM_EPOCHS):\n","#     print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n","#     epoch_loss = [0.0, 0]\n","#     for samples in train_loader:\n","#         #\n","#         images, masks = samples\n","#         images = images.to(DEVICE)\n","#         masks = masks.to(DEVICE)\n","#         #forward images to model\n","#         outputs, ou2, ou3 = model(images)\n","#         #get loss\n","#         print(outputs.shape)\n","#         print(masks.shape)\n","#         print(ou2)\n","#         print(ou3)\n","#         loss = F.cross_entropy(outputs, masks.long(), ignore_index=-1)\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         optimizer.step()\n","#         epoch_loss[0] += loss.item()\n","#         epoch_loss[1] += images.size(0)\n","\n","#     scheduler.step()\n","#     print(f'[EPOCH {epoch+1}] Avg. Loss: {epoch_loss[0] / epoch_loss[1]}')\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}